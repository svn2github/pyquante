\documentclass[twocolumn]{revtex4}

% Rick's usual macros
\newcommand{\chem}[1]{\ensuremath{\mathrm{#1}}}
\newcommand{\overlap}[2]{\ensuremath{\left\langle{#1}\left|{#2}\right\rangle\right.}}
\newcommand{\bracket}[3]{\ensuremath{\left\langle{#1}\left|{#2}\right|{#3}\right\rangle}}
\newcommand{\matvec}[1]{\ensuremath{\mathbf{#1}}}

\begin{document}

\title{PyQuante: Quantum Chemistry for Education and Exploration}
\author{Richard P. Muller}
\email{rpm@wag.caltech.edu}
\affiliation{Caltech Materials and Process Simulation Center,
Pasadena, California, 91125}
\date{\today}

\begin{abstract}
We describe the PyQuante quantum chemistry suite of programs, a
package written in the Python programming language, and designed as a
toolkit for developing and exploring quantum chemistry
techniques. This technical note details the different modules in the
program suite, how quantum chemistry programs may be built from these
modules, and discusses how and why PyQuante can be used to teach and
explore quantum chemistry.
\end{abstract}

\maketitle

\section{Introduction}
The last 40 years have seen enormous breakthroughs in both computer
power and computational algorithms. For the field of quantum
chemistry, these developments have meant that what was once a somewhat
arcane field open to the few has become a more approachable field open
to the many. A rough measure of this transformation may be obtained
from the number of quantum chemistry calculations routinely performed
by experimental organic chemists, chemical engineers, or materials
scientists. The ease of use of commercial packages such as Gaussian or
Jaguar has contributed significantly to this rise.

However, an unfortunate counterpart to the availability easy to use
quantum chemical software has been that an increasing number of
practicing scientists use these programs as \emph{black boxes},
programs whose inner workings are unknown and that are haphazzardly
chosen from pull-down menus with little care to their inner workings
or inherent accuracy.

This development is unfortunate for many reasons. First and foremost,
quantum chemistry is a fascinating and beautiful field that cannot be
appreciated without knowing something of its inner workings. These
inner workings are often perceived as being difficult to understand,
a perception resulting in a large degree from thirty year-old, hard to
follow Fortran implementations. However, despite scattered subtleties,
quantum chemistry techniques are neither hard to understand nor hard
to implement, and (at the risk of sounding like terrible nerds) a
great deal of enjoyment and satisfaction can be derived from
conceiving an then implementing a new theory. Finally, at least in the
author's experience, rarely does even the most complete quantum
chemistry package contain \emph{everything} that a working quantum
chemist requires: the solution of hard problems generally requires
creative thinking and the generation and implementation of new
methods. 

For these reasons we have developed the PyQuante quantum chemistry
program suite. PyQuante is written in the Python programming language,
a modern, structured, dynamically-typed, object-oriented language. We
chose Python because of the emphasis in the Python community of
clearly written and easy to understand programs. Python programs can
also be easily interfaced to programs written in C, Fortran, and other
programming languages, which allows the most time intensive parts of a
program to be written in a compiled language for speed. PyQuante
writes several of its integral routines in C, and also makes
use of the NumPy library of linear algebra functions such as matrix
multiplies and eigensolvers. PyQuante is available under the modified 
BSD license from the web site http://pyquante.sourceforge.net. 

This technical note introduces Python as a programming language for
scientific applications, reviews some of the main points of quantum
chemistry, describes some of the fundamental modules that are
available as building blocks in the PyQuante program suite, and
describes how these building blocks may be joined together in
Hartree-Fock (HF) or Density Functional Theory (DFT) programs. 

\section{An Extremely Brief Introduction to Python and NumPy}
The Python programming language was developed by Guido van Rossum from
??? to ??? at the ????. The program is distributed without cost under
an open-source license. A full introduction to Python is well beyond
the scope of this paper, and the reader is referred to the book
\emph{Learning Python} by ???, as well as the excellent documentation
at the Python web site (http://www.python.org). Here we will describe
some of the features that make Python particularly suitable to
scientific programming.

Python is a \emph{scripting language}, which means that Python
programs need not be compiled in a separate step, but are
automatically byte-compiled at runtime. 

Python variables can be dynamically and automatically allocated; often
the objects can be allocated and initialized in a single step. For
example, an array of 10 integers can be allocated and set to zero via
the Python command
\begin{verbatim}
    AnArray = [0]*10
\end{verbatim}
In contrast, the analogous Fortran77 code would be
\begin{verbatim}
    integer iarray,i
    dimension iarray(10)
    do i=1,10
        iarray(i) = 0
    enddo
\end{verbatim}

Python is an object-oriented programming language, which means that
programmers can create their own data objects (like the C programming
language's \emph{structs}), and these objects can have their own
functions (like C++'s \emph{classes}). For example, we could describe
an \tt{Atom} class for atoms that would allow us to create a new atom
object for a Hydrogen atom at the origin via the command
\begin{verbatim}
    AnAtom = Atom(AtomicNumber=1,
                  Position=(0,0,0))
\end{verbatim}
Later in the program, we can access the atomic number via
\begin{verbatim}
    atno = AnAtom.AtomicNumber
\end{verbatim}
and the $x$-coordinate via
\begin{verbatim}
    x = AnAtom.Position[0]
\end{verbatim}
where here the 0 refers to the first element of the position vector
(like C, the first element of a Python array is the 0th element). The
ability to define classes and implement objects in this fashion is an
important element of readable code because it allows a programmer to
collect related data elements rather than obtain the elements from a
single array.

Python comes with many auxilliary libraries containing additional
function. For example, the \emph{string} library has a \emph{split}
function that will split a string on whitespace, so that the code
\begin{verbatim}
    from string import split
    ListOfWords = split('This is a list of words')
\end{verbatim}
will produce an array containing the words
\begin{verbatim}
    ['This','is','a','list','of','words']
\end{verbatim}

The NumPy library provides linear algebra functionality much like that
in the MATLAB program. NumPy is distributed with many versions of
Python, and can also be obtained from the web site
http://numpy.sourceforge.net. A $10\times 10$ matrix of floating point
numbers can be allocated and set to zero via the NumPy library call
\begin{verbatim}
    from Numeric import zeros, Float
    A = zeros((10,10),Float)
\end{verbatim}
Matrix operations similar to MATLAB or Fortran90 are possible; for
example, two matrices A and B may be added via the command
\begin{verbatim}
    C = A + B
\end{verbatim}
and the eigenvalues of the resulting matrix may be computed via the
command 
\begin{verbatim}
    from LinearAlgebra import eigenvalues
    evals = eigenvalues(C)
\end{verbatim}

Python is in general a very readable language, and in writing the
PyQuante program suite we have taken additional efforts to make the
code as easy to understand as possible. We will thus end our survey of
the Python language here, and trust upon the aforementioned references
and the readability of the PyQuante modules for explaination of the
additional language features.

\section{An Extremely Brief Introduction to Quantum Chemistry}
In very general terms, quantum chemistry is interested in finding
solutions to the time-independent electronic Schrodinger equation for
molecules
\begin{equation}
H\Psi = E\Psi
\label{schrod}
\end{equation}
where $H$ is the many-electron Hamiltonian operator, $\Psi$ and
$E$ are the corresponding many-electron wave function and electronic
energy. (Our apologies to quantum chemists who have been excluded by
this narrow definition.) In general equation (\ref{schrod}) is not
solvable for systems with more than two electrons, and thus one
typically makes the Hartree-Fock or \emph{mean field} approximation
which assumes that electrons do not see other electrons but rather the
\emph{average field} of the oether electrons. This approximation
transforms the many-electron equation (\ref{schrod}) to many coupled
one-electron equations of the form
\begin{equation}
F\phi = \epsilon\phi.
\label{fock}
\end{equation}
Here $F$ is the \emph{Fock operator} resulting from an electron in the
field of all of the other electrons and the nuclei, and $\phi$ is one
of the one-electron \emph{orbitals}. The many-electron wave function
is the antisymmetric product of all of the occupied orbitals
\begin{equation}
\Psi = \mathcal{A}\prod_i^{N_{occ}}\phi_i\phi_i,
\end{equation}
where $\mathcal{A}$ is the \emph{antisymmetrizer operator} that insures
that the wave function obeys the Pauli principle. Here we show a
\emph{closed-shell} wave function where every orbital is doubly
occupied, but wave functions with half-occupied orbitals are also
possible. 

Technically, however, the differential equations in (\ref{fock}) are
still impossible to solve. In practice we expand each orbital $\phi$
is a linear combination of basis functions
\begin{equation}
\phi = \sum_a c_a\chi_a; 
\end{equation}
the functions have $\chi$ different three-dimensional shapes that are
akin to $s$, $p$, $d$, etc., atomic orbitals. Using this basis set
expansion the differential equations in equation (\ref{fock}) are
transformed into a matrix eigenvalue problem that may be solved using
standard linear algebra techniques. The matrix form of the Fock
equations are typically written as
\begin{equation}
\matvec{F}\matvec{c} = \matvec{S}\matvec{c}\matvec{E}
\end{equation}
where the matrix \matvec{F} corresponds to the operator $F$, the
vector \matvec{c} are the coefficients of the linear expansion of the
orbital $\phi$ in terms of the basis functions, and \matvec{S} is the
\emph{overlap matrix} that represents the spatial overlap between the
different basis functions.

The Hartree-Fock approximation works surprisingly well. However,
electrons are strongly interracting negatively charged particles, and
in some cases, most importantly when two electrons are in the same
orbital, assuming that they only see the average charge of the other
particles leads to errors called the \emph{correlation
energy}. Density Functional Theory (DFT) attempts to approximate the
correlation energy by approximating equation (\ref{fock}) and adding
an additional term. These approximations are typically either the
Local Density Approximation (LDA), proportional to the local
electronic density at every point in space, or the Generalized
Gradient Approximation (GGA), proportional to the local density and
the gradient of the local density at every point in space. In
practice, DFT techniques reproduce experimental results better than do
HF techniques. Roughly speaking, HF techniques reproduce experimental
heats of formation to within ~10 kcal/mol, whereas DFT techniques
reproduce experimental heats of formation to within ~3 kcal/mol.

More often than not we obtain energies from DFT calculations, from
which we can derive heats of formation, bond dissociation, and
potential energy surfaces for atoms and molecules. We can also obtain
the electronic charge density $\rho(r)$ from the wave function $\Psi$.
We can obtain forces on atoms from the spatial derivative of the
energy; this derivative can either be taken numerically, or, more
effectively, analytically. Using the forces we can either optimize the
geometry (that is, find the most stable geometry corresponding to an
electronic state), find a transition state between two stable
geometries (the saddle point of the lowest energy reaction path
connecting the two structures), or even run molecular dynamics.

\section{Integrals Over Gaussian Basis Functions}
The basis functions used in the linear expansion of the molecular
orbitals are generally taken to be \emph{Cartesian Gaussian
functions}, which have the form
\begin{equation}
\chi(r) = x^iy*jz^k\exp(-\alpha r^2).
\end{equation}
Here $i$, $j$, and $k$ are constants that determines the type of the
basis function (that is, $i,j = (1,0,0)$ is a $p_x$ orbital), and
$\alpha$ is an exponent that controls how tight the function
is. Gaussian functions are used because it is relatively easy to
compute the required integrals for molecular calculations using these
functions, and they describe electronic wave functions relatively well.

\section{Molecular Grids}

\section{Constructing Programs in PyQuante}

\end{document}
